{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ec16f5",
   "metadata": {},
   "source": [
    "### Building a RAG Pipeline with LangChain, Gemini, and Pinecone\n",
    "This notebook walks through the end-to-end development of a Retrieval-Augmented Generation (RAG) system using LangChain and Gemini (Google Generative AI). It demonstrates embedding generation with Google Embeddings, vector storage with Pinecone, similarity search with FAISS/Sklearn, document structuring with LangChainâ€™s Document class, and dynamic prompt chaining using LangChain Runnables. A production-ready retriever and query-answering chain are built with search thresholding and structured prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d8f8ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Environment & Warnings\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv  # For loading environment variables\n",
    "\n",
    "# ðŸ§  Embeddings & LLMs\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings  # Google Gemini & embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # HuggingFace embeddings\n",
    "\n",
    "# ðŸ§¾ Prompting & Output Parsers\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub  # LangChain Hub for prebuilt prompts\n",
    "\n",
    "# ðŸ“„ Document & Vector Store\n",
    "from langchain_core.documents import Document\n",
    "# from langchain_community.vectorstores import FAISS  # FAISS Vector Store\n",
    "# from langchain_community.docstore.in_memory import InMemoryDocstore  # In-memory docstore for FAISS\n",
    "from langchain_pinecone import PineconeVectorStore  # Pinecone integration\n",
    "\n",
    "# ðŸŒ² Pinecone Configuration\n",
    "from pinecone import Pinecone, ServerlessSpec  # Pinecone core client & serverless setup\n",
    "\n",
    "# ðŸ“Š Utils\n",
    "from uuid import uuid4  # Unique ID generator for documents\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity  # For similarity computations\n",
    "import faiss  # Facebook AI Similarity Search (FAISS)\n",
    "import pprint\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ['LANGSMITH_PROJECT'] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ['LANGSMITH_ENDPOINT'] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ['LANGSMITH_TRACING'] = os.getenv(\"LANGSMITH_TRACING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24bf20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_google = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16ac92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"India is establish player in world cricket\",\n",
    "            \"India own the ODI world cup 1983, 2011\",\n",
    "            \"India own the T20 world cup 2007, 2025\"]\n",
    "\n",
    "my_query = \"About which country we are talking here?\"\n",
    "\n",
    "document_embedding = embeddings_google.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16b9cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6355a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query_embed = embeddings_google.embed_query(my_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33971a",
   "metadata": {},
   "source": [
    "| Metric            | Similarity Score Range | Behavior                              |\n",
    "| ----------------- | ---------------------- | ------------------------------------- |\n",
    "| Cosine Similarity | \\[-1, 1]               | Focuses on angle only |\n",
    "| L2 Distance       | \\[0, âˆž)                | Focuses on **magnitude + direction**  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6c371c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57796012, 0.57769502, 0.57979686]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([my_query_embed], document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ce046e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91873741, 0.9190259 , 0.91673598]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances([my_query_embed], document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05f168fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abc685bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'learn-agenticaiv2'\n",
    "pc.has_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa1400e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e7dcbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c92b8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = pc.Index(index_name)\n",
    "\n",
    "pinecone_vs = PineconeVectorStore(index=index_name, embedding=embeddings_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4bf9d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       " Document(metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
       " Document(metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       " Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},#additional info\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c89bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42115f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0c0a5ebf-8e5d-4da5-aef2-f7a53e974012\n",
      "1\n",
      "3292c73c-f91d-42ea-92ba-43a04a1e7194\n",
      "2\n",
      "b301a809-64d3-4c16-850e-5f38a09d7f0d\n",
      "3\n",
      "fdf35423-d6b3-4c60-a7f9-1e120de6689b\n",
      "4\n",
      "5f67c457-1538-4aff-b801-8086f7c41952\n",
      "5\n",
      "f969cdef-5ce7-4a43-a283-e3d52b6f2ade\n",
      "6\n",
      "5ac2dce9-4fc9-4e93-bbd1-69d8c50caafa\n",
      "7\n",
      "54a3d14e-bfb6-4ebe-99b1-dad2f243681f\n",
      "8\n",
      "97e52599-7413-46d5-ab87-9cf0e5755c16\n",
      "9\n",
      "d88c4e9d-2554-42f3-b6e7-21e6608da53e\n"
     ]
    }
   ],
   "source": [
    "for _ in range(len(documents)):\n",
    "    print(_)\n",
    "    print(str(uuid4()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f9c7b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b8854bf4-aa6e-43d4-8782-751b80ddc6bc',\n",
       " '2a912983-4c43-4afb-823f-8392315d7096',\n",
       " '62d6401f-70f7-456b-b4d9-cb0fa82d3c33',\n",
       " '1c338dcf-14b8-4ee3-8d04-8d7b52f72a25',\n",
       " '1ac042e2-432a-49ca-be65-03511442ae69',\n",
       " 'd415b4c5-b591-4bda-aad6-4cb11e870877',\n",
       " 'a8366c53-e311-443f-8748-ad6f4dacc2ea',\n",
       " '488835d4-6337-4915-ae5b-099b0c65d9a1',\n",
       " 'd6e1bb50-ac73-4f68-93a2-782fff0b6d44',\n",
       " 'be3becd0-9984-4ab5-8729-b42e7d0b186e']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4ca05768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['76734e21-da3b-43ea-bee2-90cbc263c534',\n",
       " '3e89364e-29b6-4ed0-b9f6-a43df2fbb2cd',\n",
       " '076b8862-6b0b-411a-b373-d2894d905d03',\n",
       " 'c4560632-968b-4171-8d16-21a18f448b79',\n",
       " '0baa387d-5944-40e7-b4f0-7b6075ced66b',\n",
       " '4b36f29f-5450-4086-a628-69be55a38ddd',\n",
       " 'a2506975-672c-4c25-982a-d17d4501ae01',\n",
       " '6ce39a13-7929-4e62-a2d2-56cb5ebfd5ec',\n",
       " '5e0487a9-2c33-4b0a-9f19-6eeadf15613d',\n",
       " '4f019c92-cc0a-45d6-8c47-5834c8239c8f']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_vs.add_documents(documents=documents, id=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ba451a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='687e1025-e918-4c79-a242-be4edf4d6652', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='33e18021-5768-43a7-87be-eebf7d506c07', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='282c720e-31e8-443a-9111-8b65eba9ccc6', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pinecone_vs.similarity_search(\"what langchain provides to us?\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9887807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = pinecone_vs.as_retriever(search_type='similarity_score_threshold',\n",
    "                                     search_kwargs={'score_threshold': 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "880d6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='33e18021-5768-43a7-87be-eebf7d506c07', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='687e1025-e918-4c79-a242-be4edf4d6652', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='282c720e-31e8-443a-9111-8b65eba9ccc6', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(id='04c2afbf-92a1-4058-878f-9d5e24793f7c', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84206692",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "77b472b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "pprint.pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "210a1c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "    input_variables=['context', 'question']\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "206d3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is langchain \\nContext: langchain is very super framework for LLM. \\nAnswer:\")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({'question':'what is langchain', 'context':'langchain is very super framework for LLM.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4be772b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8d3df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5b2f986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.  The provided text expresses anxiety about deletion and advertises a LangChain project, but offers no other information.\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what you know?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
